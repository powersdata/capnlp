set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.9)
preObj
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.8)
preObj
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
suppressMessages(library(dplyr))
new_training <- training[, c(names(training)[IL_col_idx], "diagnosis")]
IL_col_idx <- grep("^[Ii][Ll].*", names(testing))
suppressMessages(library(dplyr))
new_testing <- testing[, c(names(testing)[IL_col_idx], "diagnosis")]
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
# apply the non pca model on the testing set and check the accuracy
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result
library(caret)
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
library(e1071)
install.packages("e1071")
library(e1071)
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
# apply the non pca model on the testing set and check the accuracy
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result
pc_training_obj <- preProcess(new_training[, -13], method=c('center', 'scale', 'pca'), thresh=0.8)
pc_training_preds <- predict(pc_training_obj, new_training[, -13])
pc_testing_preds <- predict(pc_training_obj, new_testing[, -13])
# compute the model with pca predictors
pca_model <- train(new_training$diagnosis ~ ., data=pc_training_preds, method="glm")
# apply the PCA model on the testing set
pca_result <- confusionMatrix(new_testing[, 13], predict(pca_model, pc_testing_preds))
pca_result
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
dim(training)
dim(testing)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(log(training$Superplasticizer+1), breaks=20)
dev.off()
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
library(caret)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
adData = data.frame(diagnosis,predictors)
dim
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
train = createDataPartition(diagnosis, p = 0.50,list=FALSE)
test = createDataPartition(diagnosis, p = 0.50,list=FALSE)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
names <- colnames(concrete)
names <- names[-length(names)]
featurePlot(x = training[, names], y = training$CompressiveStrength, plot = "pairs")
index <- seq_along(1:nrow(training))
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() +
theme_bw()
index <- seq_along(1:nrow(training))
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() +
theme_bw()
ggplot(data = training, aes(y = index, x = cutCS)) + geom_boxplot() + geom_jitter(col = "blue") +
theme_bw()
index <- seq_along(1:nrow(training))
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() +
theme_bw()
cutCS <- cut2(training$CompressiveStrength, g = 4)
summary(cutCS)
featurePlot(x = training[, names], y = training$CompressiveStrength, plot = "pairs")
index <- seq_along(1:nrow(training))
ggplot(data = training, aes(y = index, x = cutCS)) + geom_boxplot() + geom_jitter(col = "blue") +
theme_bw()
dev.off()
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
names <- colnames(concrete)
names
qplot(1:dim(training)[1],Superplasticizer,data=training,colour=cut2(1:dim(training)[1],m=200,g=4))
index <- seq_along(1:nrow(training))
cutCS <- cut2(training$CompressiveStrength, g = 4)
featurePlot(x = training[, names], y = training$CompressiveStrength, plot = "pairs")
qplot(1:dim(training)[1],Superplasticizer,data=training,colour=cut2(1:dim(training)[1],m=200,g=4))
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
index=grep("^IL(.*)",colnames(training))
alzhaimerSubset=subset(training,select=c(index))
pre=preProcess(alzhaimerSubset,thresh=0.9,method="pca")
index
alzhaimerSubset
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
index=grep("^IL(.*)",colnames(training))
alzhaimerSubset=subset(training,select=c(index))
pre <- preProcess(alzhaimerSubset,thresh=0.9,method="pca")
pre
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
index=grep("^IL(.*)",colnames(predictors)
subsetpredictors=subset(predictors,select=c(index))
index=grep("^IL(.*)",colnames(predictors))
subsetpredictors=subset(predictors,select=c(index))
adDatasub = data.frame(diagnosis,subsetpredictors)
inTrain = createDataPartition(adDatasub$diagnosis, p = 3/4)[[1]]
training = adDatasub[ inTrain,]
testing = adDatasub[-inTrain,]
m1=train(diagnosis~.,data=training,method="glm")
prediction1=predict(m1,newdata=testing)
mean(testing$diagnosis==prediction1)
m2=train(training$diagnosis~.,data=trainPC,method="glm"
prediction2=predict(m2,testPC)
m2=train(training$diagnosis~.,data=trainPC,method="glm")
pre=preProcess(training[,-1],thresh=0.8,method="pca")
trainPC=predict(pre,training[,-1])
testPC=predict(pre,testing[,-1])
m2=train(training$diagnosis~.,data=trainPC,method="glm")
prediction2=predict(m2,testPC)
confusionMatrix(testing$diagnosis,prediction2)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
library(AppliedPredictiveModeling)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
options( warn = -1 )
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
testing <- segmentationOriginal[!inTrain, ]
list = FALSE) # 60% training
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, list = FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
library(rpart)
library(ggplot2)
in2Train <- segmentationOriginal$Case=="Train"
training2 <- segmentationOriginal[inTrain, ]
testing2 <- segmentationOriginal[!inTrain, ]
training2 <- segmentationOriginal[in2Train, ]
testing2 <- segmentationOriginal[!in2Train, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(rattle)
in2Train <- segmentationOriginal$Case=="Train"
training2 <- segmentationOriginal[in2Train, ]
testing2 <- segmentationOriginal[!in2Train, ]
# 1. Subset the data to a training set and testing set based on the Case variable in the data set.
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, list = FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
fancyRpartPlot(modFit$finalModel)
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
modolive <- train(Area ~ ., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(modolive, newdata = newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
install.packages("lubridate")
install.packages("forecast")
library(ElemStatLearn)
data("vowel.test"); data("vowel.train")
head(vowel.train)
vowel.train$y <- as.factor(vowel.train)
vowel.test$y  <- as.factor(vowel.test)
str(vowel.train)
vowel.train$y <- as.factor(as.character(vowel.train))
vowel.test$y  <- as.factor(as.character(vowel.test))
set.seed(33833)
library(caret)
train?
asfd
?train
rfFit <- train(y ~ ., method = "rf", data = vowel.train)
gbmFit <- train(y ~ ., method = "gbm", data = vowel.train)
rfAcc <- predict(rfFit, newdata = vowel.test)
gbmAcc <- predict(gbmFit, newdata = vowel.test)
rfAcc
rfAcc$Accuracy
rfAcc$results
confusionMatrix(vowel.test$y, rfAcc)$overall['Accuracy']
rfAcc <- predict(rfFit, vowel.test)
confusionMatrix(vowel.test$y, rfAcc)$overall['Accuracy']
rfFit <- suppressMessages(train(y ~ ., method = "rf", data = vowel.train))
rfAcc <- predict(rfFit, vowel.test)
confusionMatrix(vowel.test$y, rfAcc)$overall['Accuracy']
rfAcc <- predict(rfFit, vowel.test$y)
confusionMatrix(rfAcc, vowel.test$y)
rfFit <- suppressMessages(train(y ~ ., method = "rf", data = vowel.train))
rfAcc <- predict(rfFit)
confusionMatrix(rfAcc, vowel.test$y)
confusionMatrix(rfAcc, vowel.train$y)
confusionMatrix(rfAcc, vowel.train$y)$overall['Accuracy']
rfAcc <- predict(rfFit, vowel.test)
confusionMatrix(rfAcc, vowel.train$y)$overall['Accuracy']
rfAcc <- predict(rfFit)
confusionMatrix(rfAcc, vowel.test$y)$overall['Accuracy']
rfAcc <- predict(rfFit)
confusionMatrix(rfAcc, vowel.test$y)$overall['Accuracy']
confusionMatrix(rfAcc, vowel.train$y)$overall['Accuracy']
rfAcc <- predict(rfFit, vowel.test$y)
testing <- vowel.test[,-1]
rfAcc <- predict(rfFit, testing)
confusionMatrix(rfAcc, vowel.train$y)$overall['Accuracy']
confusionMatrix(rfAcc, vowel.test$y)$overall['Accuracy']
confusionMatrix(rfAcc, testing)$overall['Accuracy']
rfAcc
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(caret)
library(gbm)
library(mgcv)
library(nlme)
install.packages("elasticnet")
install.packages("nlme")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(caret)
library(gbm)
library(mgcv)
library(nlme)
library(elasticnet)
prf <- predict(rf, vowel.test)
rfFit <- suppressMessages(train(y ~ ., method = "rf", data = vowel.train))
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
suppressMessages(library(caret))
set.seed(33833)
rfmodel <- suppressMessages(train(y~., data=vowel.train, method="rf"))
gbmmodel <- suppressMessages(train(y~., data=vowel.train, method="gbm"))
rf.result <- predict(rfmodel, vowel.test)
gbm.result <- predict(gbmmodel, vowel.test)
confusionMatrix(vowel.test$y, rf.result)$overall['Accuracy']
confusionMatrix(vowel.test$y, gbm.result)$overall['Accuracy']
idx_agreed <- (rf.result == gbm.result)
confusionMatrix(vowel.test$y[idx_agreed], rf.result[idx_agreed])$overall['Accuracy']
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
rfmodel <- suppressMessages(diagnosis~., data=training, method="rf")
rfmodel <- suppressMessages(train(diagnosis~., data=training, method="rf"))
gbm.result <- predict(gbmmodel, testing)
gbmmodel <- suppressMessages(train(diagnosis~., data=training, method="gbm"))
ldamodel <- suppressMessages(train(diagnosis~., data=training, method="lda"))
library(MASS)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
library(MASS)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rfmodel <- suppressMessages(train(diagnosis~., data=training, method="rf"))
gbmmodel <- suppressMessages(train(diagnosis~., data=training, method="gbm"))
ldamodel <- suppressMessages(train(diagnosis~., data=training, method="lda"))
rf.result <- predict(rfmodel, testing)
gbm.result <- predict(gbmmodel, testing)
lda.result <- predict(ldamodel, testing)
library(MASS)
library(MASS)
library(MASS)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rfmodel <- suppressMessages(train(diagnosis~., data=training, method="rf"))
gbmmodel <- suppressMessages(train(diagnosis~., data=training, method="gbm"))
ldamodel <- suppressMessages(train(diagnosis~., data=training, method="lda"))
rf.result <- predict(rfmodel, testing)
gbm.result <- predict(gbmmodel, testing)
lda.result <- predict(ldamodel, testing)
confusionMatrix(testing$diagnosis, rf.result)$overall['Accuracy']
confusionMatrix(testing$diagnosis, gbm.result)$overall['Accuracy']
confusionMatrix(testing$diagnosis, lda.result)$overall['Accuracy']
combined.data <- data.frame(rf.result, gbm.result, lda.result, diagnosis=testing$diagnosis)
combined.result <- predict(combined.model, testing)
View(combined.data)
combined.model <- train(diagnosis~., data=combined.data, method="rf")
combined.result <- predict(combined.model, testing)
confusionMatrix(testing$diagnosis, combined.result)$overall['Accuracy']
confusionMatrix(testing$diagnosis, rf.result)$overall['Accuracy']
confusionMatrix(testing$diagnosis, gbm.result)$overall['Accuracy']
confusionMatrix(testing$diagnosis, lda.result)$overall['Accuracy']
confusionMatrix(testing$diagnosis, combined.result)$overall['Accuracy']
data("concrete")
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso.model <- train(CompressiveStrength~., data=training, method="lasso")
plot.enet(lasso.model$finalModel, xvar="penalty", use.color=TRUE)
dev.off()
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
dat = read.csv("~/Desktop/gaData.csv")
dat = read.csv("~/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
visits.exp.smoothing = bats(tstrain)
?visits
?visits.exp.smoothing
modelFit3<- bats(tstrain)
plot(modelFit3)
h<- dim(testing)[1]
fcast<- forecast(modelFit3,level=95,h=h)
plot(fcast,testing$visitsTumblr)
result3 <- c()
l <- length(fcast$lower)
for (i in 1:l){
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result3 <- c(result3, a)
}
sum(result3)/l * 100
set.seed(3523)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
modelFit4<- svm(CompressiveStrength~.,data=training)
result4<- predict(modelFit4,testing)
accuracy(result4,testing$CompressiveStrength)
library(caret)
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
dev.off()
manipulate(myPlot(s), x.s = slider(0, 2, step = 0.1))
dev.off()
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), x.s = slider(0, 2, step = 0.1))
dev.off
dev.off()
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
dev.off()
require(devtools)
install_github('rCharts', 'ramnathv')
data("airquality")
dTable(airquality, sPaginationType = "full_numbers")
library(rCharts)
dTable(airquality, sPaginationType = "full_numbers")
dev.off()
install.packages(c("car", "caret", "coda", "data.table", "DiagrammeR", "evaluate", "formatR", "GGally", "git2r", "gsheet", "HistData", "htmlwidgets", "kernlab", "lavaan", "lme4", "mnormt", "nlme", "quantreg", "R.methodsS3", "R.oo", "raster", "rattle", "RcppArmadillo", "RcppEigen", "readODS", "rio", "rmarkdown", "rneos", "shiny", "sp", "withr", "XML", "xtable"))
install.packages("RWeka", dependencies = FALSE)
install.packages("RWekajars", dependencies = FALSE)
install.packages("rJava")
install.packages("RWeka")
library(rJava)
library(RWekajars)
install.packages("RWekajars", dependencies = FALSE)
install.packages("RWeka", dependencies = FALSE)
library(rJava)
library(RKEAjars)
library(RWeka)
install.packages("RKEA")
install.packages("RWeka")
load("~/GitHub/project/capnlp/nlp2.Rdata")
data()
data
class(data)
setwd("~/GitHub/capnlp")
directory <- getwd()
setwd(directory)
which_library <- "main"
source("scripts/001libraries.R")
which_function <- "main"
source("scripts/005functions.R")
which_import <- "main"
source("scripts/010imports.R")
