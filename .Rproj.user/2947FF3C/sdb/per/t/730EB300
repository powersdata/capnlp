{
    "contents" : "\n#This is the startting script for the project\ndirectory <- getwd()\nsetwd(directory)\nwhich_library <- \"main\"\nsource(\"scripts/001libraries.R\")\n\nwhich_function <- \"main\"\nsource(\"scripts/005functions.R\")\n\nwhich_import <- \"main\"\nsource(\"scripts/010imports.R\")\n\n#Load Full Corpus\nwhich_import <- \"fullcorpus\"\nsource(\"scripts/010imports.R\")\n\n#specific sample words of corpus\nsource(\"scripts/010imports.R\")\nsource(\"scripts/026sampleselection.R\")\nfindwordlist <- c(\"i'd die\", \"marital\", \"monkeys\", \"stress\", \"jury to settle the matter\", \"time to take a picture\", \"pizza\", \"asleep\")\n#findwordlist <- \"marital\"\nFind_Words(findwordlist)\nSelected_Sample()\ncsa <- Clean_Sample(\"a\")\ncsan <- Sample_Ngrams(\"a\", ngram = 4)\n\n#find next word\nsource(\"scripts/063nextword.R\")\nNext_Word(\"a\", ngram = 4, wordlist = \"but i'm\")\nNext_Word(\"a\", 5, wordlist = \"arctic monkeys this\")\nNext_Word(\"a\", ngram = 4, wordlist = \"telling me about his\")\nNext_Word(\"a\", 4, wordlist = \"I'd live and I'd\")\nNext_Word(\"a\", 4, wordlist = \"jury to settle the\")\nNext_Word(\"a\", 5, wordlist = \"settle the pizza\")\n\n\n#looking at files\nhead(a8, 25)\na8$nGram <- gsub(\"[^a-z ]\", \"\", a8$nGram)\na8$nGram <- gsub(\"(?<=[\\\\s])\\\\s*|^\\\\s+|\\\\s+$\", \"\", a8$nGram, perl=TRUE)\ncc<-csa[[2]]$content\nhead(cc,15)\n\nfindtext <- grep(\"list author\", cc[[1]]$content)\nfindtext <- grep(\"happy\", cc)\nfindtext <- grep(\"list author\", cc[[3]]$content)\n\n\n\n\n\nsource(\"scripts/042ngrams.R\")\n\n\n\n\n#data analysis\nsource(\"scripts/020data.R\")\n\n#sample corpus\nsource(\"scripts/025sample.R\")\nsamplepercent <- 0.1\nsn <- Corpus(VectorSource(write_training_text(sourceletter, samplepercent, ngram)))\n\nsource(\"scripts/030clean.R\")\ncsn <- Clean_Corpus(sn, samplepercent)\n\nsource(\"scripts/042ngrams.R\")\ncs <- csn\ncsn1 <- Corpus_to_ngram(cs, samplepercent, 1)\ncsn2 <- Corpus_to_ngram(cs, samplepercent, 2)\ncsn3 <- Corpus_to_ngram(cs, samplepercent, 3)\ncsn4 <- Corpus_to_ngram(cs, samplepercent, 4)\n\n\nsn <- Corpus(VectorSource(write_training_text(\"en_US.news.txt\", samplepercent)))\nsb <- Corpus(VectorSource(write_training_text(\"en_US.blogs.txt\", samplepercent)))\nstw <- Corpus(VectorSource(write_training_text(\"en_US.twitter.txt\", samplepercent)))\n#clean corpus\n\ncsb <- Clean_Corpus(sb, samplepercent)\ncstw <- Clean_Corpus(stw, samplepercent)\n\ncsa1 <- Clean_Corpus(a, .1)\n#csa10 <- Clean_Corpus(a, samplepercent)\n#csa20 <- Clean_Corpus(a, 20)\n\n#sample, clean and create ngrams and save to RDS\nsn <- Corpus(VectorSource(write_training_text(\"en_US.news.txt\", samplepercent)))\nsb <- Corpus(VectorSource(write_training_text(\"en_US.blogs.txt\", samplepercent)))\nstw <- Corpus(VectorSource(write_training_text(\"en_US.twitter.txt\", samplepercent)))\n\n\nwhich_function <- \"main\"\nsource(\"scripts/005functions.R\")\nsn <- SCNS(\"n\",0.1,4)\nsb <- SCNS(\"b\",5,4)\nstw <- SCNS(\"tw\",7,4)\nsa <- SCNS(\"a\", 0.1, 4)\n\nwhich_import <- \"samples\"\nsource(\"scripts/010imports.R\")\nnames(b54.rds) <- c(\"file\", \"unigram\", \"bigram\", \"trigram\", \"quadgram\")\nnames(n704.rds) <-\n        c(\"file\", \"unigram\", \"bigram\", \"trigram\", \"quadgram\")\nnames(tw74.rds) <-\n        c(\"file\", \"unigram\", \"bigram\", \"trigram\", \"quadgram\")\nfor (i in 2:5) {\n        starttime <- Sys.time()\n        x <- b54.rds[[i]]\n        y <- n704.rds[[i]]\n        z <- tw74.rds[[i]]\n        df <-\n                merge(\n                        x, y, by.x = c(\"nGram\", \"nWords\"), by.y = c(\"nGram\", \"nWords\"), all = TRUE\n                )\n        df[is.na(df)] <- 0\n        \n        df$Freq <- as.numeric(df$Freq.x) + as.numeric(df$Freq.y)\n        df <- df[-c(3, 4)]\n        \n        x <- df\n        y <- x\n        \n        df <-\n                merge(\n                        x, y, by.x = c(\"nGram\", \"nWords\"), by.y = c(\"nGram\", \"nWords\"), all = TRUE\n                )\n        df[is.na(df)] <- 0\n        \n        df$Freq <- as.numeric(df$Freq.x) + as.numeric(df$Freq.y)\n        df <- df[-c(3, 4)]\n        df <- df[order(df$Freq, decreasing = TRUE),]\n        rownames(df) <- NULL\n        rows <- 1000 * df$nWords[1]\n        df <- df[1:rows,]\n        assign (paste0(\"top\", df$nWords[1], \"gram\"), df)\n        print(paste(\n                \"TIME for\", df$nwords[1], \"merging:\", timer(starttime)\n        ))\n        rm(starttime, i , rows, filenames, x, y, z, df)\n}\n\nhead(top1gram)\nhead(top2gram, 20)\nhead(top3gram, 30)\nhead(top4gram, 40)\n\n#query\nwhich_query <- \"query\"\nsource(\"scripts/051query.R\")\n\n\n\n\n\n\n\n#selected model to test\ncsa <- csa1\ncsa <- cstw\ncsa <- csn\n\nrm(csn, csb, cstw, csa1, csa10, csa20)\n\nhead(csa4, 10)\n#Testing\norig <- stw\norig <- sn\norig <- tw\norig <- n\norig <- b\ncc <- csa\nsource(\"scripts/030clean.R\")\ncsn <- Clean_Corpus(sn, samplepercent)\ncc <- csa\n\norig[[1]]$content[1:4]\ncc[[1]]$content[1:4]\n\n\nfindtext <- grep(\"list author\", cc[[3]]$content)\n\nfor (i in c(\"tw\", \"n\", \"b\")){\n\norigtext <- grep(\"jury to settle the\", orig[[1]]$content, perl = TRUE)\norigtext\n\n\norigtext <- grep(\"\\\\b#(\\\\S*)\\\\b\", orig[[1]]$content)\n\n\ncc[[1]]$content[22]\norig[[1]]$content[22]\n\ncc[[1]]$content[head(origtext)]\norig[[1]]$content[head(origtext)]\n}\n\n# test  for \nfoundtext <- gsub(\" *\\\\b(?<![ai])\\\\p{L}{1,1}(?![ai])\\\\b *\", \" \", cc[[1]]$content[findtext], perl = TRUE)\nhead(foundtext)\n\nclean[[1]]$content[100]\ntw[[1]]$content[2720]\nn[[1]]$content[22]\nn[[1]]$content[2142]\n# atext[[1]]$content[366]\n# atext[[1]]$content[813]\n\n#Start testing over\n# rm(list=ls())\n# gc(reset=TRUE)\n\n#find text in samples\nfindtext <- grep(findwordlist, a4$nGram, perl = TRUE)\na4[head(findtext),]\n\n#find in sample clean corpus\ncc<-csa[[1]]$content\ncc<-a8$nGram\nhead(cc,15)\n\nstr_replace_all(cc, \"[^a-z ]\", \"\")\n\n\ncc<-unique(as.character(rbind(csa[[1]]$content, csa[[2]]$content)))\ncc<-unique(as.character(rbind(cc,csa[[3]]$content)))\nrownames(cc) <- NULLstr_replace_all(clean, \"[^a-z ]\", \"\")\nfindtext <- as.integer(grep(\"=\", cc))\ncc[findtext,]\nfruits <- c(\"one apple\", \"two pears\", \"three bananas\")\n\nfruits <- c(\"one2 apple\", \"1two pears\", \"thr3ee bananas\")\nstr_replace_all(fruits, \"[0-9]\", \"\")\nstr_replace_all(fruits, \"[^a-z ]\", \"\")\nstr_replace(fruits, \"([aeiou])\", \"\")\nstr_replace(fruits, \"([aeiou])\", \"\\\\1\\\\1\")\nstr_replace(fruits, \"[aeiou]\", c(\"1\", \"2\", \"3\"))\nstr_replace(fruits, c(\"a\", \"e\", \"i\"), \"-\")\nfruits <- c(\"one apple\", \"two pears\", \"three bananas\")\nstr_replace(fruits, \"[aeiou]\", \"-\")\nstr_replace_all(fruits, \"[aeiou]\", \"-\")\nstr_replace_all(fruits, \"([aeiou])\", \"\")\nstr_replace_all(fruits, \"([aeiou])\", \"\\\\1\\\\1\")\nstr_replace_all(fruits, \"[aeiou]\", c(\"1\", \"2\", \"3\"))\nstr_replace_all(fruits, c(\"a\", \"e\", \"i\"), \"-\")\n\nlastgram <- as.data.frame(word(xgram$nGram, -2))\n\n#                   xgram_tmp[order(xgram_tmp$Freq, decreasing = TRUE),]\n#                   dd[ order(-dd[,4], dd[,1]), ]\nxgram <- a16\nrn <- sort.int(sample(1:nrow(a16), 4000, replace=F))\nrn <- append(rn, as.integer(nrow(a16)-2))\nrn <- append(rn, as.integer(nrow(a16)-1))\nrn <- append(rn, as.integer(nrow(a16)))\n\n\nxgram <- xgram[rn, ]\nclean_xgram_sample <- xgram\n\nxgram <- clean_xgram_sample\nhead(xgram)\ntail(xgram)\n\n#testlast <- word(xgram$nGram, -2, -5)\n\n#lastgram <- xgram[order(word(xgram$nGram, -1)),]\n#lastgram <- xgram[order(word(xgram$nGram, -2)),]\n#lastgram <- lastgram[order(word(lastgram$nGram, -3,-2)),]\n#lastgram <- lastgram[order(word(lastgram$nGram, -4,-2)),]\n#lastgram <- lastgram[order(word(lastgram$nGram, -5,-2)),]\n\n#lastgram <- lastgram[order(word(lastgram$nGram, -6,-2)),]\n\n\nlastgram <- xgram[order(-xgram$nWords, -xgram$Freq, xgram$nGram),]\n\n#sorted <- a16[stri_sort(stri_extract_last_words(a16$nGram), opts_collator = list(numeric = TRUE))]\nhead(lastgram, 2000)\ntail(lastgram)\n\n\n=======\n#This is the startting script for the project\ndirectory <- getwd()\nsetwd(directory)\nwhich_library <- \"main\"\nsource(\"scripts/001libraries.R\")\n\nwhich_function <- \"main\"\nsource(\"scripts/005functions.R\")\n\nwhich_import <- \"main\"\nsource(\"scripts/010imports.R\")\n\n#Load Full Corpus\nwhich_import <- \"fullcorpus\"\nsource(\"scripts/010imports.R\")\n\n#specific sample words of corpus\nsource(\"scripts/010imports.R\")\nsource(\"scripts/026sampleselection.R\")\nfindwordlist <- c(\"i'd die\", \"about his marital\", \"arctic monkeys this weekend\", \"helps reduce your stress\", \"jury to settle the matter\", \"time to take a picture\")\n#findwordlist <- \"marital\"\nFind_Words(findwordlist)\nSelected_Sample()\ncsa <- Clean_Sample(\"a\")\ncsan <- Sample_Ngrams(\"a\", ngram = 6)\n\n#find next word\nsource(\"scripts/063nextword.R\")\nNext_Word(\"a\", ngram = 6, wordlist = \"but i'm\")\nNext_Word(\"a\", 6, wordlist = \"arctic monkeys this\")\nNext_Word(\"a\", ngram = 6, wordlist = \"telling me about his\")\nNext_Word(\"a\", 6, wordlist = \"I'd live and I'd\")\n\n#looking at files\nhead(a8, 25)\na8$nGram <- gsub(\"[^a-z ]\", \"\", a8$nGram)\na8$nGram <- gsub(\"(?<=[\\\\s])\\\\s*|^\\\\s+|\\\\s+$\", \"\", a8$nGram, perl=TRUE)\ncc<-csa[[2]]$content\nhead(cc,15)\n\nfindtext <- grep(\"list author\", cc[[1]]$content)\nfindtext <- grep(\"happy\", cc)\nfindtext <- grep(\"list author\", cc[[3]]$content)\n\n\n\n\n\nsource(\"scripts/042ngrams.R\")\n\n\n\n\n#data analysis\nsource(\"scripts/020data.R\")\n\n#sample corpus\nsource(\"scripts/025sample.R\")\nsamplepercent <- 0.1\nsn <- Corpus(VectorSource(write_training_text(sourceletter, samplepercent, ngram)))\n\nsource(\"scripts/030clean.R\")\ncsn <- Clean_Corpus(sn, samplepercent)\n\nsource(\"scripts/042ngrams.R\")\ncs <- csn\ncsn1 <- Corpus_to_ngram(cs, samplepercent, 1)\ncsn2 <- Corpus_to_ngram(cs, samplepercent, 2)\ncsn3 <- Corpus_to_ngram(cs, samplepercent, 3)\ncsn4 <- Corpus_to_ngram(cs, samplepercent, 4)\n\n\nsn <- Corpus(VectorSource(write_training_text(\"en_US.news.txt\", samplepercent)))\nsb <- Corpus(VectorSource(write_training_text(\"en_US.blogs.txt\", samplepercent)))\nstw <- Corpus(VectorSource(write_training_text(\"en_US.twitter.txt\", samplepercent)))\n#clean corpus\n\ncsb <- Clean_Corpus(sb, samplepercent)\ncstw <- Clean_Corpus(stw, samplepercent)\n\ncsa1 <- Clean_Corpus(a, .1)\n#csa10 <- Clean_Corpus(a, samplepercent)\n#csa20 <- Clean_Corpus(a, 20)\n\n#sample, clean and create ngrams and save to RDS\nsn <- Corpus(VectorSource(write_training_text(\"en_US.news.txt\", samplepercent)))\nsb <- Corpus(VectorSource(write_training_text(\"en_US.blogs.txt\", samplepercent)))\nstw <- Corpus(VectorSource(write_training_text(\"en_US.twitter.txt\", samplepercent)))\n\n\nwhich_function <- \"main\"\nsource(\"scripts/005functions.R\")\nsn <- SCNS(\"n\",0.1,4)\nsb <- SCNS(\"b\",5,4)\nstw <- SCNS(\"tw\",7,4)\nsa <- SCNS(\"a\", 0.1, 4)\n\nwhich_import <- \"samples\"\nsource(\"scripts/010imports.R\")\nnames(b54.rds) <- c(\"file\", \"unigram\", \"bigram\", \"trigram\", \"quadgram\")\nnames(n704.rds) <-\n        c(\"file\", \"unigram\", \"bigram\", \"trigram\", \"quadgram\")\nnames(tw74.rds) <-\n        c(\"file\", \"unigram\", \"bigram\", \"trigram\", \"quadgram\")\nfor (i in 2:5) {\n        starttime <- Sys.time()\n        x <- b54.rds[[i]]\n        y <- n704.rds[[i]]\n        z <- tw74.rds[[i]]\n        df <-\n                merge(\n                        x, y, by.x = c(\"nGram\", \"nWords\"), by.y = c(\"nGram\", \"nWords\"), all = TRUE\n                )\n        df[is.na(df)] <- 0\n        \n        df$Freq <- as.numeric(df$Freq.x) + as.numeric(df$Freq.y)\n        df <- df[-c(3, 4)]\n        \n        x <- df\n        y <- x\n        \n        df <-\n                merge(\n                        x, y, by.x = c(\"nGram\", \"nWords\"), by.y = c(\"nGram\", \"nWords\"), all = TRUE\n                )\n        df[is.na(df)] <- 0\n        \n        df$Freq <- as.numeric(df$Freq.x) + as.numeric(df$Freq.y)\n        df <- df[-c(3, 4)]\n        df <- df[order(df$Freq, decreasing = TRUE),]\n        rownames(df) <- NULL\n        rows <- 1000 * df$nWords[1]\n        df <- df[1:rows,]\n        assign (paste0(\"top\", df$nWords[1], \"gram\"), df)\n        print(paste(\n                \"TIME for\", df$nwords[1], \"merging:\", timer(starttime)\n        ))\n        rm(starttime, i , rows, filenames, x, y, z, df)\n}\n\nhead(top1gram)\nhead(top2gram, 20)\nhead(top3gram, 30)\nhead(top4gram, 40)\n\n#query\nwhich_query <- \"query\"\nsource(\"scripts/051query.R\")\n\n\n\n\n\n\n\n#selected model to test\ncsa <- csa1\ncsa <- cstw\ncsa <- csn\n\nrm(csn, csb, cstw, csa1, csa10, csa20)\n\nhead(csa4, 10)\n#Testing\norig <- stw\norig <- sn\norig <- tw\norig <- n\norig <- b\ncc <- csa\nsource(\"scripts/030clean.R\")\ncsn <- Clean_Corpus(sn, samplepercent)\ncc <- csa\n\norig[[1]]$content[1:4]\ncc[[1]]$content[1:4]\n\n\nfindtext <- grep(\"list author\", cc[[3]]$content)\n\nfor (i in c(\"tw\", \"n\", \"b\")){\n\norigtext <- grep(\"jury to settle the\", orig[[1]]$content, perl = TRUE)\norigtext\n\n\norigtext <- grep(\"\\\\b#(\\\\S*)\\\\b\", orig[[1]]$content)\n\n\ncc[[1]]$content[22]\norig[[1]]$content[22]\n\ncc[[1]]$content[head(origtext)]\norig[[1]]$content[head(origtext)]\n}\n\n# test  for \nfoundtext <- gsub(\" *\\\\b(?<![ai])\\\\p{L}{1,1}(?![ai])\\\\b *\", \" \", cc[[1]]$content[findtext], perl = TRUE)\nhead(foundtext)\n\nclean[[1]]$content[100]\ntw[[1]]$content[2720]\nn[[1]]$content[22]\nn[[1]]$content[2142]\n# atext[[1]]$content[366]\n# atext[[1]]$content[813]\n\n#Start testing over\n# rm(list=ls())\n# gc(reset=TRUE)\n\n#find text in samples\nfindtext <- grep(findwordlist, a4$nGram, perl = TRUE)\na4[head(findtext),]\n\n#find in sample clean corpus\ncc<-csa[[1]]$content\ncc<-a8$nGram\nhead(cc,15)\n\nstr_replace_all(cc, \"[^a-z ]\", \"\")\n\n\ncc<-unique(as.character(rbind(csa[[1]]$content, csa[[2]]$content)))\ncc<-unique(as.character(rbind(cc,csa[[3]]$content)))\nrownames(cc) <- NULLstr_replace_all(clean, \"[^a-z ]\", \"\")\nfindtext <- as.integer(grep(\"=\", cc))\ncc[findtext,]\nfruits <- c(\"one apple\", \"two pears\", \"three bananas\")\n\nfruits <- c(\"one2 apple\", \"1two pears\", \"thr3ee bananas\")\nstr_replace_all(fruits, \"[0-9]\", \"\")\nstr_replace_all(fruits, \"[^a-z ]\", \"\")\nstr_replace(fruits, \"([aeiou])\", \"\")\nstr_replace(fruits, \"([aeiou])\", \"\\\\1\\\\1\")\nstr_replace(fruits, \"[aeiou]\", c(\"1\", \"2\", \"3\"))\nstr_replace(fruits, c(\"a\", \"e\", \"i\"), \"-\")\nfruits <- c(\"one apple\", \"two pears\", \"three bananas\")\nstr_replace(fruits, \"[aeiou]\", \"-\")\nstr_replace_all(fruits, \"[aeiou]\", \"-\")\nstr_replace_all(fruits, \"([aeiou])\", \"\")\nstr_replace_all(fruits, \"([aeiou])\", \"\\\\1\\\\1\")\nstr_replace_all(fruits, \"[aeiou]\", c(\"1\", \"2\", \"3\"))\nstr_replace_all(fruits, c(\"a\", \"e\", \"i\"), \"-\")\n\nlastgram <- as.data.frame(word(xgram$nGram, -2))\n\n#                   xgram_tmp[order(xgram_tmp$Freq, decreasing = TRUE),]\n#                   dd[ order(-dd[,4], dd[,1]), ]\nxgram <- a16\nrn <- sort.int(sample(1:nrow(a16), 4000, replace=F))\nrn <- append(rn, as.integer(nrow(a16)-2))\nrn <- append(rn, as.integer(nrow(a16)-1))\nrn <- append(rn, as.integer(nrow(a16)))\n\n\nxgram <- xgram[rn, ]\nclean_xgram_sample <- xgram\n\nxgram <- clean_xgram_sample\nhead(xgram)\ntail(xgram)\n\n#testlast <- word(xgram$nGram, -2, -5)\n\n#lastgram <- xgram[order(word(xgram$nGram, -1)),]\n#lastgram <- xgram[order(word(xgram$nGram, -2)),]\n#lastgram <- lastgram[order(word(lastgram$nGram, -3,-2)),]\n#lastgram <- lastgram[order(word(lastgram$nGram, -4,-2)),]\n#lastgram <- lastgram[order(word(lastgram$nGram, -5,-2)),]\n\n#lastgram <- lastgram[order(word(lastgram$nGram, -6,-2)),]\n\n\nlastgram <- xgram[order(-xgram$nWords, -xgram$Freq, xgram$nGram),]\n\n#sorted <- a16[stri_sort(stri_extract_last_words(a16$nGram), opts_collator = list(numeric = TRUE))]\nhead(lastgram, 2000)\ntail(lastgram)\n\n\n>>>>>>> 004f468cdccad6b1cdbb8e587c3047875b7eb5b7\n",
    "created" : 1462362887208.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3544866144",
    "id" : "730EB300",
    "lastKnownWriteTime" : 1462362905,
    "path" : "~/GitHub/project/capnlp/001main.R",
    "project_path" : "001main.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}